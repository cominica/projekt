{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZfbQ5iPHyiK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "MAIN_DATA = pd.read_csv(\"/content/warszawa.csv\")\n",
        "\n",
        "df_warsaw = MAIN_DATA.copy()\n",
        "df_warsaw.head()\n",
        "\n",
        "!pip install spacy -U\n",
        "!python -m spacy download pl_core_news_lg\n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load(\"pl_core_news_lg\")\n",
        "nlp.pipeline\n",
        "\n",
        "import re\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Część 1 - przetwarzanie i oczyszczanie danych\n"
      ],
      "metadata": {
        "id": "CQIDxpQfIKqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Zamień skróty nazw dni tygodnia na polskie odpowiedniki (pełne nazwy dni tygodnia) - kolumna created_at\n",
        "df_warsaw.created_at = [row.replace(\"Mon\", \"poniedziałek\").replace(\"Tue\", \"wtorek\").replace(\"Wed\", \"środa\").replace(\"Thu\", \"czwartek\").replace(\"Fri\", \"piątek\").replace(\"Sat\", \"sobota\").replace(\"Sun\", \"niedziela\") for row in df_warsaw [\"created_at\"]]"
      ],
      "metadata": {
        "id": "y3vkagsnBSfc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Zamień skróty nazw miesięcy na liczbowe odpowiedniki (np Jun na 06) - kolumna user_created_at\n",
        "df_warsaw.user_created_at = [row.replace(\"Jan\", \"01\").replace(\"Feb\", \"02\").replace(\"Mar\", \"03\").replace(\"Apr\", \"04\").replace(\"May\", \"05\").replace(\"Jun\", \"06\").replace(\"Jul\", \"07\").replace(\"Aug\", \"08\").replace(\"Sep\", \"09\").replace(\"Oct\", \"10\").replace(\"Nov\", \"11\").replace(\"Dec\", \"12\") for row in df_warsaw [\"user_created_at\"]]"
      ],
      "metadata": {
        "id": "WkqBJ1SGEWe7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pobierz wszystkie linki do tweetów i przekaż je do listy (tweet_url)\n",
        "\n",
        "z = -1\n",
        "tekst =\"\"\n",
        "for el in df_warsaw:\n",
        "  z = z+1\n",
        "  doc = nlp(df_warsaw.tweet_url[z])\n",
        "  for el in doc.ents:\n",
        "    tekst = tekst + \" \" + el.text\n",
        "  \n",
        "linki_do_tweetów = re.findall(\"\\S+\", tekst)\n",
        "\n",
        "print(linki_do_tweetów)"
      ],
      "metadata": {
        "id": "uLu6mUsHvXj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pobierz wszystkie linki znajdujące się w tweetach i przekaż je do listy (kolumna urls)\n",
        "\n",
        "z = -1\n",
        "tekst = \"\"\n",
        "for el in df_warsaw:\n",
        "  z = z+1\n",
        "  if type(df_warsaw.urls[z]) == str:\n",
        "    tekst = tekst + \" \" + df_warsaw.urls[z]\n",
        "\n",
        "\n",
        "doc = nlp(tekst)\n",
        "for el in doc.ents:\n",
        "  x = x + \" \" + el.text\n",
        "\n",
        "linki_w_tweetach = re.findall(\"\\S+\", x)\n",
        "\n",
        "print(linki_w_tweetach)"
      ],
      "metadata": {
        "id": "DLJGRTSH0c8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pobierz wszystkie linki do obrazków i przekaż je do listy (kolumna media)\n",
        "\n",
        "z = -1\n",
        "tekst = \"\"\n",
        "for el in df_warsaw:\n",
        "  z = z+1\n",
        "  if type(df_warsaw.media[z]) == str:\n",
        "    tekst = tekst + \" \" + df_warsaw.media[z]\n",
        "\n",
        "doc = nlp(tekst)\n",
        "for el in doc.ents:\n",
        "  x = x + \" \" + el.text\n",
        "\n",
        "linki_do_obrazków = re.findall(\"\\S+\", x)\n",
        "print(linki_do_obrazków)"
      ],
      "metadata": {
        "id": "06k_DWxkwUIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Usuń wszystkie słowa oznaczone jako stopwords i przekaż oczyszczony tekst do nowej kolumny o nazwie text_without_stopwords\n",
        "\n",
        "def clean_text(tekst):\n",
        "  doc = nlp(tekst)\n",
        "  for token in doc:\n",
        "    x = token.text\n",
        "    if token.is_stop == True:\n",
        "      cleaned_text = tekst.replace(x, \"\")\n",
        "      return cleaned_text\n",
        "\n",
        "df_warsaw[\"text_without_stopwords\"] = df_warsaw[\"text\"].apply(clean_text)\n",
        "\n",
        "print(df_warsaw[\"text_without_stopwords\"])"
      ],
      "metadata": {
        "id": "dukZYQ5jKH9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Część 2 - eksploracyjna analiza danych"
      ],
      "metadata": {
        "id": "ln1Wj6XtLRFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetl tylko zweryfikowanych użytkowników (kolumna user_verified)\n",
        "for index, row in df_warsaw.iterrows():  \n",
        "  if row['user_verified'] != \"False\":\n",
        "    print (row['user_name'])"
      ],
      "metadata": {
        "id": "KlkcLQhgJ2CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetl tylko te tweety, które nie są uznane jako “wrażliwe” (kolumna possibly_sensitive)\n",
        "\n",
        "for index, row in df_warsaw.iterrows():  \n",
        "  if row['possibly_sensitive'] != \"True\":\n",
        "    print (row['text'])"
      ],
      "metadata": {
        "id": "UEVLluR5K_wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wypisz top5 tweetów z największa liczbą polubień.\n",
        "\n",
        "top5_polubienia = df_warsaw.nlargest(5, 'favorite_count', keep='all')\n",
        "print(top5_polubienia.text)"
      ],
      "metadata": {
        "id": "Z2LmmlPQrLOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wypisz top5 tweetów z największa liczbą retweetów.\n",
        "\n",
        "top5_retweety = df_warsaw.nlargest(5, 'retweet_count', keep='all')\n",
        "print(top5_retweety.text)"
      ],
      "metadata": {
        "id": "BDAevMv4ssT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetl tweety użytkownika, który założył konto najwcześniej (spośród wszystkich użytkowników w datasecie) (kolumna user_created_at).\n",
        "\n",
        "import datetime\n",
        "\n",
        "df_warsaw['user_created_at'] = pd.to_datetime(df_warsaw['user_created_at'])\n",
        "\n",
        "najwczesniej = df_warsaw.nsmallest(1, 'user_created_at', keep='all')\n",
        "\n",
        "print(najwczesniej.text)"
      ],
      "metadata": {
        "id": "JvxCWZ05s1-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wyświetl tweety użytkownika. który ma najwięcej followersów.\n",
        "\n",
        "najwiecej = df_warsaw.nlargest(1, 'user_followers_count', keep='all')\n",
        "\n",
        "print(najwiecej.text)"
      ],
      "metadata": {
        "id": "GUcXAd1PtAVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Podaj, w który dzień tygodnia najczęściej były publikowane tweety z datasetu\n",
        "\n",
        "df_warsaw.created_at = [row.replace(\"poniedziałek\", \"1\").replace(\"wtorek\", \"2\").replace(\"środa\", \"3\").replace(\"czwartek\", \"4\").replace(\"piątek\", \"5\").replace(\"sobota\", \"6\").replace(\"niedziela\", \"7\") for row in df_warsaw [\"created_at\"]]\n",
        "\n",
        "pn = 0\n",
        "wt = 0\n",
        "sr = 0\n",
        "cz = 0\n",
        "pt = 0\n",
        "sb = 0\n",
        "nd = 0\n",
        "\n",
        "for el in df_warsaw.created_at:\n",
        "  if el[0] == \"1\":\n",
        "    pn = pn + 1\n",
        "  elif el[0] == \"2\":\n",
        "    wt = wt + 1\n",
        "  elif el[0] == \"3\":\n",
        "    sr = sr + 1\n",
        "  elif el[0] == \"4\":\n",
        "    cz = cz + 1\n",
        "  elif el[0] == \"5\":\n",
        "    pt = pt + 1\n",
        "  elif el[0] == \"6\":\n",
        "    sb = sb + 1\n",
        "  elif el[0] == \"7\":\n",
        "    nd = nd + 1\n",
        "\n",
        "print(\"poniedziałek: \", pn)\n",
        "print(\"wtorek: \", wt)\n",
        "print(\"środa: \", sr)\n",
        "print(\"czwartek: \", cz)\n",
        "print(\"piątek: \", pt)\n",
        "print(\"sobota: \", sb)\n",
        "print(\"niedziela: \", nd)\n",
        "\n",
        "lista=[pn, wt, sr, cz, pt, sb, nd]\n",
        "\n",
        "najwieksza = None\n",
        "\n",
        "for i in lista:\n",
        "  if najwieksza == None or najwieksza < i:\n",
        "    najwieksza = i\n",
        "if najwieksza == lista[0]:\n",
        "  print(\"Najczęstszy dzień to jest poniedziałek\")\n",
        "if najwieksza == lista[1]:\n",
        "  print(\"Najczęstszy dzień to jest wtorek\")\n",
        "if najwieksza == lista[2]:\n",
        "  print(\"Najczęstszy dzień to jest środa\")\n",
        "if najwieksza == lista[3]:\n",
        "  print(\"Najczęstszy dzień to jest czwartek\")\n",
        "if najwieksza == lista[4]:\n",
        "  print(\"Najczęstszy dzień to jest piątek\")\n",
        "if najwieksza == lista[5]:\n",
        "  print(\"Najczęstszy dzień to jest sobota\")\n",
        "if najwieksza == lista[6]:\n",
        "  print(\"Najczęstszy dzień to jest niedziela\")\n"
      ],
      "metadata": {
        "id": "3iMLcYOg46_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Część 3 - przetwarzanie języka naturalnego"
      ],
      "metadata": {
        "id": "rfPAe2ZL-FLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rozpoznaj osoby (persName) i przekaż je do kolumny o nazwie persons\n",
        "#Rozpoznaj miejsca (placeName) i przekaż je do kolumny o nazwie places\n",
        "#Rozpoznaj organizacje (orgName) i przekaż je do kolumny o nazwie organizations\n",
        "\n",
        "df_warsaw[\"persons\"] = \"\"\n",
        "df_warsaw[\"places\"] = \"\"\n",
        "df_warsaw[\"organizations\"] = \"\"\n",
        "\n",
        "\n",
        "n = -1\n",
        "\n",
        "for el in df_warsaw:\n",
        "  n = n+1\n",
        "  doc = nlp(df_warsaw.text[n])\n",
        "  for el in doc.ents:\n",
        "    y = el.label_\n",
        "    x = el.text\n",
        "    if y == \"persName\":\n",
        "      df_warsaw[\"persons\"] = df_warsaw[\"persons\"] + \" \" + x\n",
        "    elif y == \"placeName\":\n",
        "      df_warsaw[\"places\"] = df_warsaw[\"places\"] + \" \" + x\n",
        "    elif y == \"orgName\":\n",
        "      df_warsaw[\"organizations\"] = df_warsaw[\"organizations\"] + \" \" + x\n",
        "\n",
        "\n",
        "print (df_warsaw[\"persons\"])\n",
        "print (df_warsaw[\"places\"])\n",
        "print (df_warsaw[\"organizations\"])"
      ],
      "metadata": {
        "id": "at-i9g8Ac0I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Część 4 - rozwiązywanie problemów/umiejętność interpretowania dokumentacji\n",
        "\n",
        "\n",
        "Wykorzystując pakiet matplotlib wykonaj wykres ilustrujący liczbę tweetów per dzień tygodnia\n",
        "\n"
      ],
      "metadata": {
        "id": "mTTkvlVePQcM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Wykorzystując pakiet matplotlib wykonaj wykres ilustrujący liczbę tweetów per dzień tygodnia\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8_7DoGlI63aV"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista=[pn, wt, sr, cz, pt, sb, nd]\n",
        "bars = ('poniedziałek', 'wtorek', 'środa', 'czwartek', 'piątek', 'sobota', 'niedziela')\n",
        "y_pos = np.arange(len(lista))\n",
        " \n",
        "plt.figure(figsize=(10,5))\n",
        " \n",
        "plt.bar(y_pos, lista, color = 'teal')\n",
        "\n",
        "plt.xticks(y_pos, bars)\n",
        " \n",
        "plt.xlabel('Dzień tygodnia', fontsize=12, color='darkslategray')\n",
        "plt.ylabel('Liczba tweetów', fontsize=12, color='darkslategray')\n",
        "plt.title('Liczba tweetów per dzień tygodnia', fontsize=16, color='black')\n",
        " \n",
        "plt.show();"
      ],
      "metadata": {
        "id": "_nHTUowS7DQo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}